{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573d5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import sys\n",
    "# sys.path.append('/home/caohainam/Review-Analytics')\n",
    "import argparse\n",
    "from unittest.util import _MAX_LENGTH\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    AutoModel, \n",
    "    AutoConfig,\n",
    "    BertModel,\n",
    "    MODEL_MAPPING,\n",
    "    CONFIG_MAPPING\n",
    ")\n",
    "import logging   \n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from prettytable import PrettyTable\n",
    "from accelerate import Accelerator\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import load_metric\n",
    "import accelerate\n",
    "import utils\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622fcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\t\tback_translation.ipynb\tmetric.pdf\t    process_data.ipynb\r\n",
      "Data_Add\tdata_train\t\tmodel_0\t\t    requirements.txt\r\n",
      "Data_seg\tdoc.txt\t\t\tmodel_1\t\t    review-analysis-v2\r\n",
      "DownstreamTask\tevaluation.ipynb\tmodel_2\t\t    utils.ipynb\r\n",
      "README.md\thardcopy.0\t\tpredict.ipynb\t    utils.py\r\n",
      "__pycache__\tkey-rnd-vps.json\tpreprocess_text.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e04a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XRT_TPU_CONFIG'] = \"localservice;0;localhost:51011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c711234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 15:23:46.863410: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-08-20 15:23:46.863465: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n",
      "08/20/2022 15:23:57 - INFO - __main__ - Distributed environment: TPU\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: xla:1\n",
      "Mixed precision type: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(accelerator.state)\n",
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "if accelerator.is_local_main_process:\\\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "\n",
    "# device = accelerator.device\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5e97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a4d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_file):\n",
    "    if '.csv' in data_file:\n",
    "        df = pd.read_csv(data_file, delimiter=',', header=0, encoding=\"utf8\")\n",
    "        df = df.dropna()\n",
    "#         sent = []\n",
    "#         for sample in df.values.tolist():\n",
    "#             sent.append(sample[0])\n",
    "#         return sent\n",
    "        sent = df['text'].tolist()\n",
    "        return sent\n",
    "    else:\n",
    "        return joblib.load(data_file)\n",
    "\n",
    "def GenericDataLoader(data, batch_size, max_model_length):\n",
    "    ids = []\n",
    "    masks = []\n",
    "    max_length = min(max_model_length, max_seq_length)\n",
    "    for sent in data:\n",
    "        try:\n",
    "            inputs = tokenizer(sent, return_tensors=\"np\", padding='max_length', truncation=True, max_length=max_length)\n",
    "            encoded_sent = inputs['input_ids'][0]\n",
    "            mask = inputs['attention_mask'][0]\n",
    "            ids.append(encoded_sent)\n",
    "            masks.append(mask)\n",
    "        except:\n",
    "            print(sent)\n",
    "    inputs = torch.tensor(np.array(ids))\n",
    "    masks = torch.tensor(np.array(masks))\n",
    "    data = TensorDataset(inputs, masks)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "def predict(model, test_dataloader, num_test_sample):\n",
    "\n",
    "    model.eval()\n",
    "    targets, preds = [], []\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        outputs = accelerator.gather([logits])\n",
    "        preds.append(logits)\n",
    "    logit_preds = torch.cat(preds)[:num_test_sample*36]\n",
    "    score_preds = utils.convert_logits(logit_preds).reshape(-1, 6).to(device) # ko co to(device) thi sieu lau, why?\n",
    "    return logit_preds, score_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f281ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = 'Data_Add/19-8_khachsan.csv'\n",
    "# test_file = 'Data_Add/19-8_vanchuyen.csv'\n",
    "test_file = 'Data_Add/19-8_all-topic.csv'\n",
    "model_name_or_path = 'model_0/model_with_remake_data'\n",
    "max_seq_length = 512\n",
    "num_labels = 36\n",
    "per_device_eval_batch_size = 64\n",
    "tokenizer_name = 'xlm-roberta-base'\n",
    "# device = 'cpu'\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80cf439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_0/model_with_remake_data/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_with_remake_data\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_with_remake_data/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_with_remake_data.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /home/caohainam/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /home/caohainam/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels).to(device)\n",
    "config = model.config\n",
    "max_model_length = config.max_position_embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fcc29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_data(test_file)\n",
    "num_test_sample = len(test_data)\n",
    "test_dataloader = GenericDataLoader(test_data, per_device_eval_batch_size, max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7a4c4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_dataloader\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(test_dataloader))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ac637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = ['không gian hiện đại phục vu chu đáo']\n",
    "# num_test_sample = len(test_data)\n",
    "# test_dataloader = GenericDataLoader(test_data, per_device_eval_batch_size, max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94652d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [00:34<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "logit_preds, score_preds = predict(model, test_dataloader, num_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7a996ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6857, 36])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fe2c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6857, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd027c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for i in range(logit_preds.shape[0]):\n",
    "#         logit = logit_preds[i].to('cpu')\n",
    "#         if any(utils.get_confidence(logit_preds[0])) < 0.8:\n",
    "#             print(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bdfbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     predict_ = predict_.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95676a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_preds = logit_preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd363321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko chay duoc =))\n",
    "score_preds = score_preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c5e0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence(logit):\n",
    "    # input: tensor\n",
    "    conf = []\n",
    "    for i in range(0, 36, 6):\n",
    "        x = torch.tensor(logit[i:i+6])    \n",
    "#         print(type(x))\n",
    "        x = round(max(torch.nn.functional.softmax(x, dim=0).tolist()), 4)\n",
    "        conf.append(x)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a0f6f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for idx, i in enumerate(logit_preds):\n",
    "    count += 1\n",
    "    conf = get_confidence(i)\n",
    "#     print(conf)\n",
    "    if any(t < 0.8 for t in conf):\n",
    "#         print(test_data[idx])\n",
    "        res.append([test_data[idx]] + )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f8653f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>giai_tri</th>\n",
       "      <th>luu_tru</th>\n",
       "      <th>nha_hang</th>\n",
       "      <th>an_uong</th>\n",
       "      <th>van_chuyen</th>\n",
       "      <th>mua_sam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4417</td>\n",
       "      <td>Phòng ốc ở đây rộng rãi Công ty mình rất hay t...</td>\n",
       "      <td>4_all-topic.txt</td>\n",
       "      <td>4454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4418</td>\n",
       "      <td>Chủ quán dễ thương lắm. Nhà cô có vườn dâu nữa...</td>\n",
       "      <td>4_all-topic.txt</td>\n",
       "      <td>4455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4419</td>\n",
       "      <td>Hôm nay đi hội sách cv Thống Nhất nè , cv siêu...</td>\n",
       "      <td>4_all-topic.txt</td>\n",
       "      <td>4456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4420</td>\n",
       "      <td>Ko gian ngoài trời thoáng mát. Bánh pizza to t...</td>\n",
       "      <td>4_all-topic.txt</td>\n",
       "      <td>4457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421</td>\n",
       "      <td>Mình mới giặt sấy ở cửa hàng Laundromat TTV nà...</td>\n",
       "      <td>4_all-topic.txt</td>\n",
       "      <td>4458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0        4417  Phòng ốc ở đây rộng rãi Công ty mình rất hay t...   \n",
       "1        4418  Chủ quán dễ thương lắm. Nhà cô có vườn dâu nữa...   \n",
       "2        4419  Hôm nay đi hội sách cv Thống Nhất nè , cv siêu...   \n",
       "3        4420  Ko gian ngoài trời thoáng mát. Bánh pizza to t...   \n",
       "4        4421  Mình mới giặt sấy ở cửa hàng Laundromat TTV nà...   \n",
       "\n",
       "          location    id  giai_tri  luu_tru  nha_hang  an_uong  van_chuyen  \\\n",
       "0  4_all-topic.txt  4454         0        0         0        0           0   \n",
       "1  4_all-topic.txt  4455         0        0         0        0           0   \n",
       "2  4_all-topic.txt  4456         0        0         0        0           0   \n",
       "3  4_all-topic.txt  4457         0        0         0        0           0   \n",
       "4  4_all-topic.txt  4458         0        0         0        0           0   \n",
       "\n",
       "   mua_sam  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(test_file, delimiter=',', header=0, encoding=\"utf8\")\n",
    "df = df.dropna()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d23dd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'giai_tri', 'luu_tru', 'nha_hang', 'an_uong', 'van_chuyen', 'mua_sam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9fd49ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = {'giai_tri': [], \n",
    "         'luu_tru': [],\n",
    "         'nha_hang': [],\n",
    "         'an_uong': [],\n",
    "         'van_chuyen': [],\n",
    "         'mua_sam': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088eccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(add_df.keys())\n",
    "for i in predict_:\n",
    "    score = (i.tolist())\n",
    "    for i, key in enumerate(keys):\n",
    "        add_df[key].append(score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8bf125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giai_tri</th>\n",
       "      <th>luu_tru</th>\n",
       "      <th>nha_hang</th>\n",
       "      <th>an_uong</th>\n",
       "      <th>van_chuyen</th>\n",
       "      <th>mua_sam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   giai_tri  luu_tru  nha_hang  an_uong  van_chuyen  mua_sam\n",
       "0         4        0         0        0           0        0\n",
       "1         0        0         0        0           3        0\n",
       "2         0        0         0        0           4        0\n",
       "3         0        0         0        0           3        3\n",
       "4         0        0         0        0           3        0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_df = pd.DataFrame(add_df)\n",
    "add_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7aab5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(add_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8317972",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df, add_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68561eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>giai_tri</th>\n",
       "      <th>luu_tru</th>\n",
       "      <th>nha_hang</th>\n",
       "      <th>an_uong</th>\n",
       "      <th>van_chuyen</th>\n",
       "      <th>mua_sam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Một chuyến đi thật tuyệt vời và học được nhiều...</td>\n",
       "      <td>3_vanchuyen.txt</td>\n",
       "      <td>11326</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xe thoải mái. Đến lúc đêm nhưng lái xe không đ...</td>\n",
       "      <td>3_vanchuyen.txt</td>\n",
       "      <td>11327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thẻ tiện lợi dễ sử dụng và dễ đổi ở sân bay.</td>\n",
       "      <td>3_vanchuyen.txt</td>\n",
       "      <td>11328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mình không dùng visa thanh toán mà chọn t...</td>\n",
       "      <td>3_vanchuyen.txt</td>\n",
       "      <td>11329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mua vé của travel phải in ra vé mới được đi tàu.</td>\n",
       "      <td>3_vanchuyen.txt</td>\n",
       "      <td>11330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         location     id  \\\n",
       "0  Một chuyến đi thật tuyệt vời và học được nhiều...  3_vanchuyen.txt  11326   \n",
       "1  Xe thoải mái. Đến lúc đêm nhưng lái xe không đ...  3_vanchuyen.txt  11327   \n",
       "2       Thẻ tiện lợi dễ sử dụng và dễ đổi ở sân bay.  3_vanchuyen.txt  11328   \n",
       "3  Mình không dùng visa thanh toán mà chọn t...  3_vanchuyen.txt  11329   \n",
       "4   Mua vé của travel phải in ra vé mới được đi tàu.  3_vanchuyen.txt  11330   \n",
       "\n",
       "   giai_tri  luu_tru  nha_hang  an_uong  van_chuyen  mua_sam  \n",
       "0         4        0         0        0           0        0  \n",
       "1         0        0         0        0           3        0  \n",
       "2         0        0         0        0           4        0  \n",
       "3         0        0         0        0           3        3  \n",
       "4         0        0         0        0           3        0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09823ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('Data_Add/vanchuyen_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a948b298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615fabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303c74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff2769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9f17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_logit(logit):\n",
    "    res = []\n",
    "    for i in range(0, 36, 6):\n",
    "        x = logit[i:i+6]\n",
    "        res.append(torch.argmax(x))\n",
    "    res = torch.stack(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d257e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 4, 0, 0, 0]\n",
      "{'review': 'không gian hiện đại phục vu chu đáo', 'results': {'giai_tri': 0, 'luu_tru': 0, 'nha_hang': 4, 'an_uong': 0, 'di_chuyen': 0, 'mua_sam': 0}}\n"
     ]
    }
   ],
   "source": [
    "review_sentence = 'không gian hiện đại phục vu chu đáo'\n",
    "input = tokenizer(review_sentence, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=300).to(device)\n",
    "logit = model(**input)[0][0]\n",
    "# print(logit.shape)\n",
    "# predict_results = utils.convert_logits(logit).reshape(-1, 6)[0].tolist()\n",
    "predict_results = convert_logit(logit).tolist()\n",
    "print(predict_results)\n",
    "RATING_ASPECTS = [\"giai_tri\", \"luu_tru\", \"nha_hang\", \"an_uong\", \"di_chuyen\", \"mua_sam\"]\n",
    "output = {\n",
    "        \"review\": review_sentence,\n",
    "        \"results\": {}\n",
    "      }\n",
    "for count, r in enumerate(RATING_ASPECTS):\n",
    "    output[\"results\"][r] = predict_results[count]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93d046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5854df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = []\n",
    "with torch.no_grad():\n",
    "    logit = logit.to('cpu')\n",
    "    for i in range(0, 36, 6):\n",
    "        x = logit[i:i+6]    \n",
    "#         print(type(x))\n",
    "        x = round(max(torch.nn.functional.softmax(x, dim=0).tolist()), 4)\n",
    "        conf.append(x)\n",
    "if any(conf) < 0.7:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962fc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9a12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98af115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b6c8bee",
   "metadata": {},
   "source": [
    "# So sánh 2 model classification va regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57475c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_logit_to_score(logit):\n",
    "    res = []\n",
    "    for i in range(0, 36, 6):\n",
    "        x = logit[i:i+6]\n",
    "        res.append(x.index(max(x)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d88abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = 'Data_Add/19-8_khachsan.csv'\n",
    "# test_file = 'Data_Add/19-8_vanchuyen.csv'\n",
    "test_file = 'Data/test_1.z'\n",
    "model_name_or_path = 'model_0/model_with_remake_data'\n",
    "max_seq_length = 512\n",
    "num_labels = 36\n",
    "per_device_eval_batch_size = 64\n",
    "tokenizer_name = 'xlm-roberta-base'\n",
    "# device = 'cpu'\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10a4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = read_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd36822d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /home/caohainam/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /home/caohainam/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34efc91c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_0/model_classification/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_classification\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_classification/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_classification.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24a9890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_0/model_classification/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_classification\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_classification/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_classification.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 55min 36s, sys: 9min 4s, total: 3h 4min 40s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = AutoModelForSequenceClassification.from_pretrained('model_0/model_classification')\n",
    "res_classification = []\n",
    "for idx, sample in enumerate(testdata):\n",
    "    label = convert_logit_to_score(sample[1])\n",
    "    input = tokenizer(sample[0], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=300)\n",
    "    with torch.no_grad():\n",
    "        logit = model(**input)[0][0].tolist()\n",
    "    pred = convert_logit_to_score(logit)\n",
    "    if not utils.compare_arrays(label, pred):\n",
    "        res_classification.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2496285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_0/model_regression/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_regression\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_regression/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_regression.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 57min 28s, sys: 9min 29s, total: 3h 6min 58s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = AutoModelForSequenceClassification.from_pretrained('model_0/model_regression')\n",
    "res_regression = []\n",
    "for idx, sample in enumerate(testdata):\n",
    "    label = convert_logit_to_score(sample[1])\n",
    "    input = tokenizer(sample[0], return_tensors=\"pt\", padding='max_length', truncation=True, max_length=300)\n",
    "#     print(input)\n",
    "    with torch.no_grad():\n",
    "        logit = model(**input)[0][0]\n",
    "    pred = torch.round(5*torch.sigmoid(logit))\n",
    "    if not utils.compare_arrays(label, pred):\n",
    "        res_regression.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5ac2c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f70ee6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2c34673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in res_classification:\n",
    "    if i not in res_regression:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f19ca0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in res_regression:\n",
    "    if i not in res_classification:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76927dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
