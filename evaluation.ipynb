{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62136876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import sys\n",
    "import argparse\n",
    "from unittest.util import _MAX_LENGTH\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    AutoModel, \n",
    "    AutoConfig,\n",
    "    BertModel,\n",
    "    MODEL_MAPPING,\n",
    "    CONFIG_MAPPING\n",
    ")\n",
    "import logging   \n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from prettytable import PrettyTable\n",
    "from accelerate import Accelerator\n",
    "from transformers.utils.versions import require_version\n",
    "from datasets import load_metric\n",
    "import accelerate\n",
    "import utils\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36a01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XRT_TPU_CONFIG'] = \"localservice;0;localhost:51011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd551ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 01:22:15.613672: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "08/22/2022 01:22:28 - INFO - __main__ - Distributed environment: TPU\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: xla:1\n",
      "Mixed precision type: no\n",
      "\n",
      "2022-08-22 01:22:15.613724: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(accelerator.state)\n",
    "logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "if accelerator.is_local_main_process:\\\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "\n",
    "device = accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fbab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_0/model_classification/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_classification\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_classification/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_classification.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n",
      "loading configuration file model_0/model_regression/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"model_0/model_regression\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file model_0/model_regression/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at model_0/model_regression.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /home/caohainam/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /home/caohainam/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /home/caohainam/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_classification = AutoModelForSequenceClassification.from_pretrained('model_0/model_classification').to(device)\n",
    "model_regression = AutoModelForSequenceClassification.from_pretrained('model_0/model_regression').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ce7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_eval_batch_size = 64\n",
    "# test_file = 'Data/clean-public.z'\n",
    "test_file = 'Data/test_1.z'\n",
    "max_model_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae7ab17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "data = joblib.load(test_file)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d93036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9fc0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenericDataLoader(data, batch_size, max_model_length):\n",
    "    ids = []\n",
    "    masks = []\n",
    "    labels = []\n",
    "#     max_length = min(max_model_length, args.max_seq_length)\n",
    "    for sample in data:\n",
    "        sent = sample[0]\n",
    "#             if len(sent) < 5:\n",
    "#                 continue\n",
    "        inputs = tokenizer(sent, return_tensors=\"np\", padding='max_length', truncation=True, max_length=max_model_length)\n",
    "        encoded_sent = inputs['input_ids'][0]\n",
    "        mask = inputs['attention_mask'][0]\n",
    "        ids.append(encoded_sent)\n",
    "        masks.append(mask)\n",
    "        labels.append(sample[1])\n",
    "    inputs = torch.tensor(np.array(ids))\n",
    "    masks = torch.tensor(np.array(masks))\n",
    "#         labels = torch.tensor(np.array([i[1] for i in data]), dtype=torch.float)\n",
    "    labels = torch.tensor(np.array(labels), dtype=torch.float)\n",
    "    data = TensorDataset(inputs, masks, labels)\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64b6cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, test_dataloader, model_type=None):\n",
    "\n",
    "        model.eval()\n",
    "        targets, preds = [], []\n",
    "        for batch in tqdm(test_dataloader):\n",
    "\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask)\n",
    "            logits = outputs[0]\n",
    "            outputs, labels = accelerator.gather([logits, b_labels])\n",
    "            \n",
    "            targets.append(labels)\n",
    "            preds.append(outputs)\n",
    "            \n",
    "        targets = torch.cat(targets)\n",
    "        preds = torch.cat(preds)\n",
    "        \n",
    "        targets = utils.convert_logits(targets)\n",
    "        if model_type == 'classification':\n",
    "            preds = utils.convert_logits(preds)\n",
    "        elif model_type == 'regression':\n",
    "            preds = torch.round(5*torch.sigmoid(preds))\n",
    "        score =  utils.calculate_score(targets, preds)\n",
    "            \n",
    "        return round(score, 4), preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d4c0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = GenericDataLoader(data, per_device_eval_batch_size, max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2b60199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# trước khi sửa\n",
    "score_cls, pred_cls, targets = evaluation(model_classification, test_dataloader, model_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb21460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# trước khi sửa\n",
    "score_reg, pred_reg, _ = evaluation(model_regression, test_dataloader, model_type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87a68c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7593\n",
      "0.7133\n"
     ]
    }
   ],
   "source": [
    "print(score_cls)\n",
    "print(score_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b93472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls = pred_cls.tolist()\n",
    "pred_reg = pred_reg.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "646a2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4a6de27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5477ff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_reg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45a47a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i, j in zip(pred_cls, pred_reg):\n",
    "    res.append([max(x_i, x_j) for (x_i, x_j) in zip(i,j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b93377ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04c81d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7239846388498942"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.calculate_score(res, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e94e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766df091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b8a01f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1edaa7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = GenericDataLoader(data, per_device_eval_batch_size, max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b557eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 6])\n",
      "torch.Size([1000, 6])\n"
     ]
    }
   ],
   "source": [
    "model_classification.eval()\n",
    "targets, preds = [], []\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model_classification(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    outputs, labels = accelerator.gather([logits, b_labels])\n",
    "\n",
    "    targets.append(labels)\n",
    "    preds.append(outputs)\n",
    "\n",
    "targets = torch.cat(targets)\n",
    "preds = torch.cat(preds)\n",
    "\n",
    "targets = utils.convert_logits(targets)\n",
    "preds = utils.convert_logits(preds)\n",
    "\n",
    "print(targets.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17bd1d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "targets = targets.tolist()\n",
    "preds = preds.tolist()\n",
    "print(len(targets))\n",
    "print(len(targets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "807f2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sân mới được nâng cấp, sạch và mới, đặc biệt là mặt sân. Phần chỗ ngồi đa phần không có ghế, ngồi bệ xi măng.\n",
      "[5, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[0][0])\n",
    "print(targets[0])\n",
    "print(preds[0])\n",
    "utils.compare_arrays(targets[0], preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6cd0947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>giai_tri</th>\n",
       "      <th>luu_tru</th>\n",
       "      <th>nha_hang</th>\n",
       "      <th>an_uong</th>\n",
       "      <th>van_chuyen</th>\n",
       "      <th>mua_sam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sân mới được nâng cấp, sạch và mới, đặc biệt l...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phòng cách âm không được tốt cho lắm, tiếng xả...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quán rộng, thoáng mát, hải sản tươi sống, giá ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhân viên thân thiện. có ăn sáng kèm giá phòng...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chỗ nghỉ ok nhưng ace không nên ăn ở quán ngay...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nhân viên dễ thương, nhiệt tình</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cân nhắc khi đến đây. Mang tiếng bar mà đồ uốn...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hồ bơi hơi bẩn và để không đó hơi lãng phí.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thật sự chưa thấy chổ nào cho thuê xe máy nhiệ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Đồ hợp gu với giới trẻ, giá ổn không quá cao, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  giai_tri  luu_tru  \\\n",
       "0  Sân mới được nâng cấp, sạch và mới, đặc biệt l...         5        0   \n",
       "1  Phòng cách âm không được tốt cho lắm, tiếng xả...         0        2   \n",
       "2  Quán rộng, thoáng mát, hải sản tươi sống, giá ...         0        0   \n",
       "3  nhân viên thân thiện. có ăn sáng kèm giá phòng...         0        4   \n",
       "4  Chỗ nghỉ ok nhưng ace không nên ăn ở quán ngay...         0        4   \n",
       "5                    Nhân viên dễ thương, nhiệt tình         0        5   \n",
       "6  Cân nhắc khi đến đây. Mang tiếng bar mà đồ uốn...         3        0   \n",
       "7        Hồ bơi hơi bẩn và để không đó hơi lãng phí.         1        0   \n",
       "8  Thật sự chưa thấy chổ nào cho thuê xe máy nhiệ...         0        0   \n",
       "9  Đồ hợp gu với giới trẻ, giá ổn không quá cao, ...         0        0   \n",
       "\n",
       "   nha_hang  an_uong  van_chuyen  mua_sam  \n",
       "0         0        0           0        0  \n",
       "1         0        0           0        0  \n",
       "2         0        5           0        0  \n",
       "3         0        0           0        0  \n",
       "4         0        2           0        0  \n",
       "5         5        0           0        0  \n",
       "6         0        2           0        0  \n",
       "7         0        0           0        0  \n",
       "8         0        0           4        0  \n",
       "9         0        0           0        4  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/test_1.csv')\n",
    "columns = df.columns.tolist()\n",
    "df = df[columns[:7]]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baf3a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for t, p in zip(targets, preds):\n",
    "    if utils.compare_arrays(t, p):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee345b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "pre_c = ['pre_'+i for i in columns[1:]]\n",
    "x = [columns[0]]\n",
    "for i,j in zip(columns[1:], pre_c):\n",
    "    x.append(i)\n",
    "    x.append(j)\n",
    "x.append('correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae4141a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns=x)\n",
    "df1['review'] = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bca732a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82974bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for sample, t, p in zip(data, targets, preds):\n",
    "    res = []\n",
    "    res.append(sample[0])\n",
    "    for i,j in zip(t, p):\n",
    "        res.append(i)\n",
    "        res.append(j)\n",
    "    if utils.compare_arrays(t, p):\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "#     print(res)\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3aa95f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5d8a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(results, columns=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd2f5961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>giai_tri</th>\n",
       "      <th>pre_giai_tri</th>\n",
       "      <th>luu_tru</th>\n",
       "      <th>pre_luu_tru</th>\n",
       "      <th>nha_hang</th>\n",
       "      <th>pre_nha_hang</th>\n",
       "      <th>an_uong</th>\n",
       "      <th>pre_an_uong</th>\n",
       "      <th>van_chuyen</th>\n",
       "      <th>pre_van_chuyen</th>\n",
       "      <th>mua_sam</th>\n",
       "      <th>pre_mua_sam</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sân mới được nâng cấp, sạch và mới, đặc biệt l...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phòng cách âm không được tốt cho lắm, tiếng xả...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quán rộng, thoáng mát, hải sản tươi sống, giá ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhân viên thân thiện. có ăn sáng kèm giá phòng...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chỗ nghỉ ok nhưng ace không nên ăn ở quán ngay...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nhân viên dễ thương, nhiệt tình</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cân nhắc khi đến đây. Mang tiếng bar mà đồ uốn...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hồ bơi hơi bẩn và để không đó hơi lãng phí.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thật sự chưa thấy chổ nào cho thuê xe máy nhiệ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Đồ hợp gu với giới trẻ, giá ổn không quá cao, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  giai_tri  pre_giai_tri  \\\n",
       "0  Sân mới được nâng cấp, sạch và mới, đặc biệt l...         5             0   \n",
       "1  Phòng cách âm không được tốt cho lắm, tiếng xả...         0             0   \n",
       "2  Quán rộng, thoáng mát, hải sản tươi sống, giá ...         0             0   \n",
       "3  nhân viên thân thiện. có ăn sáng kèm giá phòng...         0             0   \n",
       "4  Chỗ nghỉ ok nhưng ace không nên ăn ở quán ngay...         0             0   \n",
       "5                    Nhân viên dễ thương, nhiệt tình         0             0   \n",
       "6  Cân nhắc khi đến đây. Mang tiếng bar mà đồ uốn...         3             3   \n",
       "7        Hồ bơi hơi bẩn và để không đó hơi lãng phí.         1             2   \n",
       "8  Thật sự chưa thấy chổ nào cho thuê xe máy nhiệ...         0             0   \n",
       "9  Đồ hợp gu với giới trẻ, giá ổn không quá cao, ...         0             0   \n",
       "\n",
       "   luu_tru  pre_luu_tru  nha_hang  pre_nha_hang  an_uong  pre_an_uong  \\\n",
       "0        0            0         0             0        0            0   \n",
       "1        2            1         0             0        0            0   \n",
       "2        0            0         0             5        5            5   \n",
       "3        4            4         0             0        0            0   \n",
       "4        4            0         0             0        2            3   \n",
       "5        5            5         5             5        0            0   \n",
       "6        0            0         0             3        2            2   \n",
       "7        0            0         0             0        0            0   \n",
       "8        0            0         0             0        0            0   \n",
       "9        0            0         0             0        0            0   \n",
       "\n",
       "   van_chuyen  pre_van_chuyen  mua_sam  pre_mua_sam  correct  \n",
       "0           0               0        0            0        0  \n",
       "1           0               0        0            0        0  \n",
       "2           0               0        0            0        0  \n",
       "3           0               0        0            0        1  \n",
       "4           0               0        0            0        0  \n",
       "5           0               0        0            0        1  \n",
       "6           0               0        0            0        0  \n",
       "7           0               0        0            0        0  \n",
       "8           4               5        0            0        0  \n",
       "9           0               0        4            5        0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2274ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('Data/compare_label_and_predict_test_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f031146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95e56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38fa02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect_targets = []\n",
    "# aspect_preds = []\n",
    "# for t, p in zip(targets, preds):\n",
    "#     aspect_targets.append([1 if i > 0 else 0 for i in t])\n",
    "#     aspect_preds.append([1 if i > 0 else 0 for i in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1564b9e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# aspects = ['vui chơi', 'lưu trú', 'nhà hàng', 'ăn uống', 'vận chuyển', 'mua sắm']\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(15,10))\n",
    "# # ax.plot(x, y)\n",
    "# count = 0\n",
    "# for i in range(6):\n",
    "#     for j in range(i+1, 6):\n",
    "#         target = [p[i] for p in aspect_targets]\n",
    "#         pred = [t[i] for t in aspect_preds]\n",
    "# #         plot_confusion_matrix(conf_mat=binary,\n",
    "# #                               ax=axes.flatten()[count], \n",
    "                                \n",
    "# #                               cmap='Blues',\n",
    "# #                              cdisplay_labels=[aspects[i], aspects[j]])\n",
    "# #         ax.title.set_text(aspects[i]+'and'+aspects[j])\n",
    "# #         count += 1\n",
    "#         break\n",
    "#     break\n",
    "# # plt.tight_layout()  \n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9fe169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(cm,\n",
    "#                           target_names,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=None,\n",
    "#                           normalize=True):\n",
    "#     \"\"\"\n",
    "#     given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "#     Arguments\n",
    "#     ---------\n",
    "#     cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "#     target_names: given classification classes such as [0, 1, 2]\n",
    "#                   the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "#     title:        the text to display at the top of the matrix\n",
    "\n",
    "#     cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "#                   see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "#                   plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "#     normalize:    If False, plot the raw numbers\n",
    "#                   If True, plot the proportions\n",
    "\n",
    "#     Usage\n",
    "#     -----\n",
    "#     plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "#                                                               # sklearn.metrics.confusion_matrix\n",
    "#                           normalize    = True,                # show proportions\n",
    "#                           target_names = y_labels_vals,       # list of names of the classes\n",
    "#                           title        = best_estimator_name) # title of graph\n",
    "\n",
    "#     Citiation\n",
    "#     ---------\n",
    "#     http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import numpy as np\n",
    "#     import itertools\n",
    "\n",
    "#     accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "#     misclass = 1 - accuracy\n",
    "\n",
    "#     if cmap is None:\n",
    "#         cmap = plt.get_cmap('Blues')\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "\n",
    "#     if target_names is not None:\n",
    "#         tick_marks = np.arange(len(target_names))\n",
    "#         plt.xticks(tick_marks, target_names, rotation=45)\n",
    "#         plt.yticks(tick_marks, target_names)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "#     thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         if normalize:\n",
    "#             plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#         else:\n",
    "#             plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "#                      horizontalalignment=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378699a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.metrics import plot_confusion_matrix\n",
    "# aspects = ['vui chơi', 'lưu trú', 'nhà hàng', 'ăn uống', 'vận chuyển', 'mua sắm']\n",
    "\n",
    "# # fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(15,10))\n",
    "# # ax.plot(x, y)\n",
    "# count = 0\n",
    "# for i in range(6):\n",
    "#     for j in range(i+1, 6):\n",
    "#         target = [p[i] for p in aspect_targets]\n",
    "#         pred = [t[i] for t in aspect_preds]\n",
    "#         print(len(target))\n",
    "#         print(len(pred))\n",
    "#         plot_confusion_matrix(cm           = np.array([target, pred]), \n",
    "#                       normalize    = True,\n",
    "#                       target_names = [aspects[i], aspects[j]],\n",
    "#                       title        = \"Confusion Matrix, Normalized\")\n",
    "#         break\n",
    "#     break\n",
    "# # plt.tight_layout()  \n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e74f9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58106a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
